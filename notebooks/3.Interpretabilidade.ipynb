{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "if \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "    print(f\"Changed working directory to {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from beer_color_prediction import config\n",
    "\n",
    "\n",
    "def slugify(s):\n",
    "    return re.sub(r\"\\W+\", \"_\", s).lower().strip(\"_\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(config.RAW_DATA_DIR / \"dataset.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"Date/Time\"])\n",
    "df = df.set_index(\"Job ID\")\n",
    "df.columns = [slugify(col) for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo do problema é entender quais variáveis influenciam na cor da cerveja Amstel, para isso, separamos de antemão o subconjunto em dados da Heineken e da Amstel. Como a coloração não pode ser negativa e há presença de valores faltantes, removemos essas amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"color\"])\n",
    "df = df.query(\"color >= 0\")\n",
    "df_amstel = df.query(\"product == 'AMST'\")\n",
    "df_heineken = df.query(\"product == 'HNK'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amstel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heineken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos de antemão um teste (gold) contendo apenas amostras da Amstel e um treino (train) contendo amostras de ambas marcas. Esse subconjunto será utilizado nas análises da predição do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_amstel.sample(frac=0.2, random_state=42)\n",
    "df_amstel = df_amstel.drop(df_test.index)\n",
    "df = df.drop(df_test.index)\n",
    "df_test.shape, df_amstel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    root_mean_squared_error,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return mse, rmse, r2, mae, mape\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    mse, rmse, r2, mae, mape = evaluate(y_true, y_pred)\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R^2: {r2:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MAPE: {mape:.2f}\")\n",
    "\n",
    "\n",
    "def preprocess_data(\n",
    "    data: pd.DataFrame,\n",
    "    handle_negative_values: str = \"keep\",\n",
    "    handle_outliers: str = \"keep\",\n",
    "    outlier_threshold: float = 1.5,\n",
    "    lower_percentile: float = 0.05,\n",
    "    upper_percentile: float = 0.95,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses the input DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        handle_negative_values (str, optional): How to handle negative values. Defaults to \"keep\".\n",
    "        Options: \"keep\", \"replace_with_zero\", \"replace_with_nan\", \"drop\".\n",
    "        handle_outliers (str, optional): How to handle outliers. Defaults to \"keep\".\n",
    "        Options: \"keep\", \"clip\", \"replace_with_nan\", \"drop\".\n",
    "        outlier_threshold (float, optional): Threshold for outlier detection. Defaults to 1.5.\n",
    "        lower_percentile (float, optional): Lower percentile for outlier detection. Defaults to 0.05.\n",
    "        upper_percentile (float, optional): Upper percentile for outlier detection. Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.drop(columns=[\"product\", \"roast_color\"], errors=\"ignore\")\n",
    "\n",
    "    if handle_negative_values == \"replace_with_zero\":\n",
    "        data = data.clip(lower=0)\n",
    "    elif handle_negative_values == \"replace_with_nan\":\n",
    "        data = data.where(data >= 0)\n",
    "    elif handle_negative_values == \"drop\":\n",
    "        data = data[(data >= 0).all(axis=1)]\n",
    "\n",
    "    if (\n",
    "        handle_outliers == \"clip\"\n",
    "        or handle_outliers == \"replace_with_nan\"\n",
    "        or handle_outliers == \"drop\"\n",
    "    ):\n",
    "        iqrs = data.quantile(upper_percentile) - data.quantile(lower_percentile)\n",
    "        lower_bound = data.quantile(lower_percentile) - outlier_threshold * iqrs\n",
    "        upper_bound = data.quantile(upper_percentile) + outlier_threshold * iqrs\n",
    "        if handle_outliers == \"clip\":\n",
    "            data = data.clip(lower=lower_bound, upper=upper_bound, axis=1)\n",
    "        elif handle_outliers == \"replace_with_nan\":\n",
    "            data = data.where((data >= lower_bound) & (data <= upper_bound))\n",
    "        elif handle_outliers == \"drop\":\n",
    "            data = data[((data >= lower_bound) & (data <= upper_bound)).all(axis=1)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer()),\n",
    "        (\"scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"regressor\", ExtraTreesRegressor(random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pipe = TransformedTargetRegressor(\n",
    "#     regressor=pipe,\n",
    "#     transformer=preprocessing.RobustScaler(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = preprocess_data(\n",
    "    df,\n",
    "    handle_negative_values=\"clip\",\n",
    "    handle_outliers=\"clip\",\n",
    ")\n",
    "\n",
    "X_train = df_train.drop(columns=[\"color\"])\n",
    "y_train = df_train[\"color\"]\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "df_test = preprocess_data(\n",
    "    df_test,\n",
    "    handle_negative_values=\"clip\",\n",
    "    handle_outliers=\"clip\",\n",
    ")\n",
    "X_test = df_test.drop(columns=[\"color\"])\n",
    "y_test = df_test[\"color\"]\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps[\"regressor\"].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = pipe.named_steps[\"regressor\"].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alguns plots de shap\n",
    "import shap\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pipe.named_steps[\"imputer\"].transform(X_train)\n",
    "X_train_transformed = pipe.named_steps[\"scaler\"].transform(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(pipe.named_steps[\"regressor\"])\n",
    "shap_values = explainer(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance de acordo com shap\n",
    "shap.summary_plot(shap_values, X_train_transformed, plot_type=\"bar\",feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train_transformed,feature_names=X_train.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
